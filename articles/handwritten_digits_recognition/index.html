<!DOCTYPE html>
<html>
  <head>
  <title>numpy で Neural Network | tyamagu2.xyz</title>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0" />
  <meta name="mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="author" content="Tomoki Yamaguchi">
  <meta property="og:site_name" content="tyamagu2.xyz">
  <meta property="og:url" content="http://tyamagu2.xyz/articles/handwritten_digits_recognition/">
  
    <meta property="og:type" content="article" />
    <meta property="og:article:author" content="Tomoki Yamaguchi" />
    <meta property="og:title" content="numpy で Neural Network">
    <meta property="og:article:published_time" content="2016-03-27T10:46:59&#43;09:00" />
  
  <link rel="canonical" href="http://tyamagu2.xyz/articles/handwritten_digits_recognition/" />
  <link href="" rel="alternate" type="application/rss+xml" title="tyamagu2.xyz" />
  <link href="" rel="feed" type="application/rss+xml" title="tyamagu2.xyz" />
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
</head>

  <body>
    <header id="site-header">
  <div class="container">
    <h1 class="site-title">
      <a href="http://tyamagu2.xyz" alt="tyamagu2.xyz">tyamagu2.xyz</a>
    </h1>
    <p class="pull-right header-links">
      <a href="" type="application/rss+xml" target="_blank"><i class="fa fa-rss"></i></a>
      <a href="https://github.com/tyamagu2"><i class="fa fa-github"></i></a>
      <a href="https://twitter.com/tyamagu2"><i class="fa fa-twitter"></i></a>
    </p>
  </div>
</header>

    <main class="container">
      <article>
        <header class="article-header">
          <h2><a href="http://tyamagu2.xyz/articles/handwritten_digits_recognition/">numpy で Neural Network</a></h2>
          <p class="article-pubtime">March 27, 2016</p>
        </header>
        <div class="article-body">
          

<p>1月から <a href="https://www.coursera.org/learn/machine-learning/">Coursera の Machine Learning のコース</a>を受講していて、先日すべての課題を提出した。
前評判通り、分かりやすくてとても良いコースだった。</p>

<p><br></p>

<p><a href="https://gyazo.com/d85bca5456116786cd7fa9e8b2a4f99c"><img src="https://i.gyazo.com/d85bca5456116786cd7fa9e8b2a4f99c.png" alt="https://gyazo.com/d85bca5456116786cd7fa9e8b2a4f99c" /></a></p>

<p><br></p>

<p>このコースでは <a href="https://www.gnu.org/software/octave/">GNU Octave</a> を使うんだけど、
やっぱり numpy つかってやってみたいよねー、ってことで、復習も兼ねて numpy で Neural Network を作ってみた。</p>

<p>最終結果は github と heroku にあげておいた。</p>

<ul>
<li><a href="https://github.com/tyamagu2/nnhw">https://github.com/tyamagu2/nnhw</a></li>
<li><a href="https://nnhw.herokuapp.com/">https://nnhw.herokuapp.com/</a></li>
</ul>

<h3 id="neural-network-で学習">Neural Network で学習</h3>

<p>題材はコースと同じく手書きの数字認識。学習データには定番の <a href="http://yann.lecun.com/exdb/mnist/">MNIST のデータセット</a>を使った。</p>

<p>Neural Network の構成は input layer、hidden layer 1 つ、output layer の 3 層。
input layer には 28 x 28 の画像をそのまま渡すことにしたので、bias unit も合わせて 28 * 28 + 1 = 785 ユニット。
feature reduction とかはやってない。
hidden layer は 30 ~ 100 ユニットぐらいで試してみた。output layer は数字の分の 10 ユニット。
Regularization の lambda とか learning rate はいくつか試して適当に決めてしまった。あんまり検証はしてない。</p>

<p>最初は batch gradient descent、つまり全学習データを一気に Neural Network に丸投げしていたんだけど、
それだと全然精度が出なかったので、mini-batch gradient descent で 500 個ずつ画像を渡すようにした。
batch gradient descent の時もコスト関数は収束しているようだったので、local optima にハマったのかなー。</p>

<p>そんな感じで自分の MacBook Pro で 20 分も学習させたところ、MNIST のテストセットで 90 ~ 95% ぐらいは精度が出た。
ちなみに、数字ごとの各ピクセルの平均値を出して、ピクセルごとの差分を使って最小二乗法で分類、
というシンプルなやり方だと 82% ぐらい。なのでそれよりはマシな結果になった。</p>

<h3 id="手書き文字を-canvas-で入力">手書き文字を Canvas で入力</h3>

<p>やっぱりインタラクティブじゃないとねー、ということで、Canvas に書いた文字を認識させるようにした。
Canvas の内容を 28 x 28 にダウンサイズして Neural Network に渡している。
Web アプリのフレームワークには flask を使ってみた。
本当はダウンサイズした画像を表示したり、output layer の数値を表示したり、とかやろうかと思ったけど、
フロントエンドでいい感じに表示するのもめんどくさくて、シンプルに結果だけ表示することにした。</p>

<p><br></p>

<p><img src="https://camo.githubusercontent.com/8d63997affda3ed7108119e2ac513af5f52279c3/687474703a2f2f692e696d6775722e636f6d2f6f4978614931422e676966" alt="gif" /></p>

<p>実際には上の gif のようにバッチリ分類はしてくれない。それでも、ピクセルごとの差分の最小二乗法よりはマシな精度になったけど。</p>

<h3 id="heroku-にデプロイ">Heroku にデプロイ</h3>

<p>せっかくなので Heroku にデプロイすることにしたけど、ここで予定外と時間を使ってしまった。</p>

<p>実は今回の Neural Network では scipy も使っている。
具体的には、sigmoid 関数として <code>scipy.special.expit</code> を使っている。そこだけ。
これは <code>1.0 / (1.0  + np.exp(-x))</code> ってやれば numpy でも計算できる。
でも x がある程度大きい負の数だと <code>np.exp(-x)</code> がオーバーフローしてしまって精度が出なかった。
<code>math.exp(-x)</code> でも同様だった。</p>

<p>そういうわけで、heroku でも scipy をインストールしないといけないんだけど、試しに deploy したら、
heroku には scipy をインストール出来ないと言われてしまった。
調べたら <a href="https://devcenter.heroku.com/articles/python-c-deps">third party 製の buildpack を使えよ</a>、とのことだったので、
<a href="https://github.com/kennethreitz/conda-buildpack">conda-buildpack</a> なるものを使うことにした。
そうすると今度は conda というパッケージマネージャーを使う必要が出てきた。
それまでは全部 pip で管理してたので、pyenv で miniconda を入れて、conda でパッケージインストールして、
とやったところ、今度は flask が起動しなくなった。werkzeug がインストール済みなのにインポートできないと言われた。
しょうがないから flask は pip で管理して、numpy と scipy は conda で管理することにした。</p>

<p>さて改めて heroku にデプロイ、したら今度は slug size が 300MB を超えてデプロイできなかった。
調べていたら<a href="https://github.com/kennethreitz/conda-buildpack/issues/21">こんな Issue</a> が見つかった。
<a href="https://www.continuum.io/blog/developer-blog/anaconda-25-release-now-mkl-optimizations">この Announcement</a> にも色々書いてあるけど、
mkl optimized な numpy/scipy を、optimize されてない nomkl version の numpy/scipy にしたらサイズが小さくなるので大丈夫とのこと。
というわけで nomkl 版にしてデプロイ成功。</p>

<h3 id="感想">感想</h3>

<p>やっぱり実データだと全然精度が出ない。どこかにしょーもないバグがあるかもしれないけど、まあこんなもんなんだろうなと思う。</p>

<p>いくつか推測した原因：</p>

<ol>
<li><p>学習データの偏り<br>
いくつか学習データを表示してみた感じだと、日本人の書く数字とはちょっと感じが違う気がした。
たまたま表示したデータがそうなのかもしれないし、実際のところは分からない。
もっと regularization の lambda の調整が必要なのかもしれないし、さらに学習データを増やすべきなのかもしれない。</p></li>

<li><p>入力画像のプリプロセス不足<br>
不足というか何もしてない。中心やサイズの調整をしてあげると結果も違ってきそう。</p></li>
</ol>

<p>結局実用まで持って行くには、lambda や hidden layer の数やユニット数などのパラメータの調整、
それを助けるためのグラフを書いたりするスクリプト、実用的な速度を出すための feature selection、
色々な学習データの収集やらプリプロセスなどの泥臭い作業、なんかが必要になってくるんだろうなーと思った。
当然だけど Machine Learning とか Neural Network とか Deep Learning とかの響きに惹かれてるだけじゃ難しいですね。
数学ももっと勉強しないと。</p>

<p>MNIST は簡単すぎるので、<a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a> というデータセットでやってみると良いと教えてもらった。
こっちだと 50% ぐらいしかでない。これで 90% 出せたらすごいらしい。</p>

<p>あと <a href="http://neuralnetworksanddeeplearning.com/">Neural Networks and Deep Learning</a> っていう Online Book が良いらしい。
この本で色々勉強しつつ、CIFAR-10 にチャレンジするなり、もうちょっと違う何かに取り組むなりやってみようかなー。</p>

        </div>
        <div class="social">
  <a class="twitter-share-button" href="https://twitter.com/intent/tweet" data-via="tyamagu2">Tweet</a>
</div>

      </article>
    </main>
    <footer id="site-footer">
  <div class="container">
    <hr>
  </div>
</footer>

<script>
  if (document.location.hostname.search('tyamagu2.xyz') !== -1) {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-71787010-1', 'auto');
    ga('send', 'pageview');
  }
</script>


<script>window.twttr = (function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0],
  t = window.twttr || {};
  if (d.getElementById(id)) return t;
  js = d.createElement(s);
  js.id = id;
  js.src = "https://platform.twitter.com/widgets.js";
  fjs.parentNode.insertBefore(js, fjs);

  t._e = [];
  t.ready = function(f) {
  t._e.push(f);
  };

  return t;
  }(document, "script", "twitter-wjs"));
</script>

  </body>
</html>
